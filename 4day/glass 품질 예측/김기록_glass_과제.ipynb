{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "김기록 glass 과제",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Mx1B7poHOgT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('glass.csv')"
      ],
      "metadata": {
        "id": "y2S9fcQ1HYHx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리"
      ],
      "metadata": {
        "id": "be6CA-32R1_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data=df.iloc[:,:-1]\n",
        "y_data=df[['Type']]"
      ],
      "metadata": {
        "id": "o3T_YGMZHa5W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 표준화"
      ],
      "metadata": {
        "id": "CXBJuoZ2Rwey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(x_data)"
      ],
      "metadata": {
        "id": "4ODYgr2qIKGq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트 트레인 스플릿"
      ],
      "metadata": {
        "id": "l06ZI1xURyFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(scaled,y_data,test_size=0.2,random_state=121)"
      ],
      "metadata": {
        "id": "Iqj1zEUVHbe2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 검증 함수"
      ],
      "metadata": {
        "id": "n0iksukcRhgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score,f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가 \n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
      ],
      "metadata": {
        "id": "6JCVlYG_OM1z"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_cv.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx9JfqlBNPYS",
        "outputId": "c0d885cd-464c-4234-ddeb-ecec1104b5c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv': 2,\n",
              " 'error_score': nan,\n",
              " 'estimator': RandomForestClassifier(random_state=0),\n",
              " 'estimator__bootstrap': True,\n",
              " 'estimator__ccp_alpha': 0.0,\n",
              " 'estimator__class_weight': None,\n",
              " 'estimator__criterion': 'gini',\n",
              " 'estimator__max_depth': None,\n",
              " 'estimator__max_features': 'auto',\n",
              " 'estimator__max_leaf_nodes': None,\n",
              " 'estimator__max_samples': None,\n",
              " 'estimator__min_impurity_decrease': 0.0,\n",
              " 'estimator__min_samples_leaf': 1,\n",
              " 'estimator__min_samples_split': 2,\n",
              " 'estimator__min_weight_fraction_leaf': 0.0,\n",
              " 'estimator__n_estimators': 100,\n",
              " 'estimator__n_jobs': None,\n",
              " 'estimator__oob_score': False,\n",
              " 'estimator__random_state': 0,\n",
              " 'estimator__verbose': 0,\n",
              " 'estimator__warm_start': False,\n",
              " 'n_jobs': -1,\n",
              " 'param_grid': {'max_depth': [6, 8, 10, 12, 13, 14],\n",
              "  'min_samples_leaf': [3, 4, 5, 6],\n",
              "  'min_samples_split': [1, 2, 3, 4, 5, 6],\n",
              "  'n_estimators': [90, 100, 110, 120]},\n",
              " 'pre_dispatch': '2*n_jobs',\n",
              " 'refit': True,\n",
              " 'return_train_score': False,\n",
              " 'scoring': None,\n",
              " 'verbose': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정트리 및 개별모델"
      ],
      "metadata": {
        "id": "01qwuhfDUVe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 의사결정나무"
      ],
      "metadata": {
        "id": "cCvN8nQ_TkTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "dt_clf.fit(X_train , y_train)\n",
        "dt_pred=dt_clf.predict(X_test)\n",
        "accuracy_score(y_test,dt_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPPx6a0QTnJ5",
        "outputId": "bbc75008-db70-4046-c54a-ce229b688022"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6744186046511628"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 회귀"
      ],
      "metadata": {
        "id": "tEnla-gyUZA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=156)\n",
        "lr.fit(X_train , y_train)\n",
        "lr_pred=lr.predict(X_test)"
      ],
      "metadata": {
        "id": "VXNsydWsUbyG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## knn근접\n",
        "    - 어떤 데이터가 주어지면 그 주변(이웃)의 데이터를 살펴본 뒤 더 많은 데이터가 포함되어 있는 범주로 분류하는 방식\n",
        "    - K: 참고할 이웃의 수. 기본값은 5"
      ],
      "metadata": {
        "id": "jEkjsEgkVU2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
        "\n",
        "classifiers = [lr, knn_clf]\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train , y_train)\n",
        "    pred = classifier.predict(X_test)\n",
        "    class_name= classifier.__class__.__name__\n",
        "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bia5DUP0VWT8",
        "outputId": "01e6c9d8-2650-4553-da99-c665eee82d81"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 정확도: 0.4884\n",
            "KNeighborsClassifier 정확도: 0.5581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#앙상블"
      ],
      "metadata": {
        "id": "3i-y8nKfSefJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VotingClassifier"
      ],
      "metadata": {
        "id": "S46IJdcPWCtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "vo_clf = VotingClassifier( estimators=[('LR',lr),('KNN',knn_clf)] , voting='soft' )\n",
        "\n",
        "vo_clf.fit(X_train , y_train)\n",
        "pred = vo_clf.predict(X_test)\n",
        "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8XaAXHrVtSD",
        "outputId": "b8417836-ef07-4c05-9826-86d856d86c66"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting 분류기 정확도: 0.5814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM(보팅)\n",
        "  - 보팅: 서로 다른 알고리즘 여러개 결합. 선형회귀, K 최근접 이웃, SVM 알고리즘 등 다양한 알고리즘을 결합하여 만든다.\n",
        "    - 하드 보팅: 다수 분류기가 결정한 예측을 선택\n",
        "    - 소프트 보팅: 분류기들의 레이블 결정 확률의 평균을 내어 이 중 가장 큰 확률의 레이블 선택\n",
        "    - svm\n",
        "      - 결정 경계(Decision Boundary), 즉 분류를 위한 기준 선을 정의하는 모델\n",
        "최적의 경계를 찾는 것이 목적\n",
        "      - 분류하는 데이터들 사이의 마진이 최대가 되는 선이 좋다    "
      ],
      "metadata": {
        "id": "U_20ncmFMP1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('svm 정확도:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucepp2UlLLQo",
        "outputId": "a6011334-a8c9-4b59-b469-c47cefb6465c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm 정확도: 0.6511627906976745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomForestClassifier(배깅)\n",
        "  - 배깅: 같은 알고리즘 여러개 결합. 랜덤 포레스트 알고리즘이 이에 속함\n",
        "      - 랜덤 포레스트: 대표적 배깅 알고리즘으로 빠르고 예측 성능이 좋다 결정트리 여러개로 구성.\n",
        "      - 각 분류기는 서로 다른 데이터셋을 학습하지만 일부 데이터는 중첩되어 있다. 이를 부트스트래핑이라 함."
      ],
      "metadata": {
        "id": "t3KETpfsRqni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# randomforestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf_clf=RandomForestClassifier(random_state=0)\n",
        "rf_clf.fit(X_train,y_train)\n",
        "pred=rf_clf.predict(X_test)\n",
        "accuracy_score(y_test,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqEWcMXEJEeY",
        "outputId": "7e414c72-50ae-427b-ba43-1e30bdff9d71"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6511627906976745"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nbclwVjcRnT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV(최적파라미터찾기)"
      ],
      "metadata": {
        "id": "LGHWGtnJRnou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'n_estimators':[90],\n",
        "    'max_depth' : [6], \n",
        "    'min_samples_leaf' : [6,7,8],\n",
        "    'min_samples_split' : [6,7,8]\n",
        "}\n",
        "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
        "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
        "grid_cv.fit(X_train , y_train)\n",
        "\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh0FyYhVJte3",
        "outputId": "7b663ce6-3e0b-4c4b-f164-976bd10a734f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 6, 'n_estimators': 90}\n",
            "최고 예측 정확도: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "print('GridSearchCV 정확도: {0:.4f}'.format(gb_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0WrcmSHMYxF",
        "outputId": "719201b5-51c6-4240-caea-0efd6df1ff34"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV 정확도: 0.6047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBClassifier(부스팅)\n",
        "    - 여러 약한 학습기가 순차적으로 느슨하게 분류하고 오분류된 데이터에 대해 가중치를 부여하여, 예측 결정 기준을 모두 결합해 예측을 수행\n",
        "    - 가중치 업데이트를 경사 하강법을 이용"
      ],
      "metadata": {
        "id": "kReyZDaQRd1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import time\n",
        "\n",
        "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
        "start_time = time.time()\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(random_state=0)\n",
        "gb_clf.fit(X_train , y_train)\n",
        "gb_pred = gb_clf.predict(X_test)\n",
        "print(gb_pred)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "\n",
        "print('GBClassifier 정확도: {0:.4f}'.format(gb_accuracy))\n",
        "print(\"GBClassifier 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pXYKwzdOVcM",
        "outputId": "06cc212c-568b-47af-d389-d8cd0853ff06"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 2 2 1 2 1 1 7 2 3 1 7 2 2 1 2 5 1 1 1 1 1 1 1 1 1 1 1 2 1 1 3 1 7 1 2\n",
            " 3 1 3 2 1 2]\n",
            "GBClassifier 정확도: 0.6279\n",
            "GBClassifier 수행 시간: 0.7 초 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## xgboost(0,1로 해야해서 불가능)\n",
        "\n",
        "    - GBM에 기반하고 있고, 단점인 느린 수행 시간 및 과적합 등의 문제를 해결했으며 특히 병렬 학습이 가능해 기존 GBM보다 빠른 학습이 가능하다.\n",
        "    - 뛰어난 예측 성능\n",
        "    - GBM 대비 빠른 수행 시간\n",
        "    - 과적합 규제\n",
        "    - 나무 가지치기: 의미 없는 분할 제거\n",
        "    - 결손값 자체 처리\n",
        "    - 자체 내장된 교차 검증"
      ],
      "metadata": {
        "id": "KPTnbRcpR5Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "dtrain = xgb.DMatrix(data=X_train , label=y_train)\n",
        "dtest = xgb.DMatrix(data=X_test , label=y_test)\n",
        "params = { 'max_depth':3,\n",
        "           'eta': 0.1,\n",
        "           'objective':'binary:logistic',\n",
        "           'eval_metric':'logloss'\n",
        "        }\n",
        "num_rounds = 400\n",
        "\n",
        "wlist = [(dtrain,'train'),(dtest,'eval') ]\n",
        "\n",
        "xgb_model = xgb.train(params = params , dtrain=dtrain , num_boost_round=num_rounds ,early_stopping_rounds=100, evals=wlist )\n",
        "pred_probs = xgb_model.predict(dtest)\n",
        "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
        "print(np.round(pred_probs[:10],3))\n",
        "\n",
        "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장 \n",
        "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
        "print('예측값 10개만 표시:',preds[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "FgL6SL4-L_An",
        "outputId": "2150f8ef-9331-4cec-88aa-e15565fa841a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-e761280013b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mwlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rounds\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwlist\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [07:54:20] /workspace/src/objective/regression_obj.cu:101: label must be in [0,1] for logistic regression\nStack trace:\n  [bt] (0) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7fe3e7133cb4]\n  [bt] (1) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::obj::RegLossObj<xgboost::obj::LogisticClassification>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*)+0x805) [0x7fe3e733d9d5]\n  [bt] (2) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x345) [0x7fe3e71cd505]\n  [bt] (3) /usr/local/lib/python3.7/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7fe3e7130aa5]\n  [bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe41f8c8dae]\n  [bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7fe41f8c871f]\n  [bt] (6) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x28c) [0x7fe41fadc5bc]\n  [bt] (7) /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x109e3) [0x7fe41fadb9e3]\n  [bt] (8) /usr/bin/python3(_PyObject_FastCallKeywords+0x92) [0x56152cf5ab32]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "    - XGBoost보다 학습 시간이 훨씬 적고 메모리 사용량도 작다. 하지만 적은 데이터 세트에 적용할 경우 과적합이 쉽게 발생하는 단점이 있다.\n",
        "    - 앞서 살펴본 알고리즘들은 균형 트리를 생성하느라 시간 및 비용이 많이 드는 단점을 극복하기 위해 리프 중심 트리 분할 방법을 사용한다. 이 방법은 균형을 맞추지 않고 계속 분할을 진행하여 트리 깊이가 깊어지고 비대칭 트리가 생성된다.\n",
        "    - 더 빠른 학습과 예측 수행 시간\n",
        "    - 더 작은 메모리 사용량\n",
        "    - 카테고리형 피처의 자동 변환과 최적 분할"
      ],
      "metadata": {
        "id": "vxIvsKz0WhtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
        "\n",
        "\n",
        "evals = [(X_test, y_test)]\n",
        "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
        "                 eval_set=evals, verbose=True)\n",
        "lgbm_preds = lgbm_wrapper.predict(X_test)\n",
        "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
        "accuracy_score(y_test,lgbm_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwzGLa2hWgm4",
        "outputId": "9630bb3a-b255-447b-9bd1-0d546baf680d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's multi_logloss: 1.59588\tvalid_0's multi_logloss: 1.59588\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 1.54822\tvalid_0's multi_logloss: 1.54822\n",
            "[3]\tvalid_0's multi_logloss: 1.50823\tvalid_0's multi_logloss: 1.50823\n",
            "[4]\tvalid_0's multi_logloss: 1.46851\tvalid_0's multi_logloss: 1.46851\n",
            "[5]\tvalid_0's multi_logloss: 1.42718\tvalid_0's multi_logloss: 1.42718\n",
            "[6]\tvalid_0's multi_logloss: 1.39311\tvalid_0's multi_logloss: 1.39311\n",
            "[7]\tvalid_0's multi_logloss: 1.36452\tvalid_0's multi_logloss: 1.36452\n",
            "[8]\tvalid_0's multi_logloss: 1.34061\tvalid_0's multi_logloss: 1.34061\n",
            "[9]\tvalid_0's multi_logloss: 1.30484\tvalid_0's multi_logloss: 1.30484\n",
            "[10]\tvalid_0's multi_logloss: 1.29024\tvalid_0's multi_logloss: 1.29024\n",
            "[11]\tvalid_0's multi_logloss: 1.27821\tvalid_0's multi_logloss: 1.27821\n",
            "[12]\tvalid_0's multi_logloss: 1.26077\tvalid_0's multi_logloss: 1.26077\n",
            "[13]\tvalid_0's multi_logloss: 1.23598\tvalid_0's multi_logloss: 1.23598\n",
            "[14]\tvalid_0's multi_logloss: 1.23079\tvalid_0's multi_logloss: 1.23079\n",
            "[15]\tvalid_0's multi_logloss: 1.22195\tvalid_0's multi_logloss: 1.22195\n",
            "[16]\tvalid_0's multi_logloss: 1.20254\tvalid_0's multi_logloss: 1.20254\n",
            "[17]\tvalid_0's multi_logloss: 1.204\tvalid_0's multi_logloss: 1.204\n",
            "[18]\tvalid_0's multi_logloss: 1.19321\tvalid_0's multi_logloss: 1.19321\n",
            "[19]\tvalid_0's multi_logloss: 1.19547\tvalid_0's multi_logloss: 1.19547\n",
            "[20]\tvalid_0's multi_logloss: 1.19393\tvalid_0's multi_logloss: 1.19393\n",
            "[21]\tvalid_0's multi_logloss: 1.18415\tvalid_0's multi_logloss: 1.18415\n",
            "[22]\tvalid_0's multi_logloss: 1.18032\tvalid_0's multi_logloss: 1.18032\n",
            "[23]\tvalid_0's multi_logloss: 1.17277\tvalid_0's multi_logloss: 1.17277\n",
            "[24]\tvalid_0's multi_logloss: 1.16246\tvalid_0's multi_logloss: 1.16246\n",
            "[25]\tvalid_0's multi_logloss: 1.1636\tvalid_0's multi_logloss: 1.1636\n",
            "[26]\tvalid_0's multi_logloss: 1.16427\tvalid_0's multi_logloss: 1.16427\n",
            "[27]\tvalid_0's multi_logloss: 1.16066\tvalid_0's multi_logloss: 1.16066\n",
            "[28]\tvalid_0's multi_logloss: 1.15\tvalid_0's multi_logloss: 1.15\n",
            "[29]\tvalid_0's multi_logloss: 1.14301\tvalid_0's multi_logloss: 1.14301\n",
            "[30]\tvalid_0's multi_logloss: 1.14113\tvalid_0's multi_logloss: 1.14113\n",
            "[31]\tvalid_0's multi_logloss: 1.1379\tvalid_0's multi_logloss: 1.1379\n",
            "[32]\tvalid_0's multi_logloss: 1.12794\tvalid_0's multi_logloss: 1.12794\n",
            "[33]\tvalid_0's multi_logloss: 1.13114\tvalid_0's multi_logloss: 1.13114\n",
            "[34]\tvalid_0's multi_logloss: 1.13124\tvalid_0's multi_logloss: 1.13124\n",
            "[35]\tvalid_0's multi_logloss: 1.12767\tvalid_0's multi_logloss: 1.12767\n",
            "[36]\tvalid_0's multi_logloss: 1.12009\tvalid_0's multi_logloss: 1.12009\n",
            "[37]\tvalid_0's multi_logloss: 1.12013\tvalid_0's multi_logloss: 1.12013\n",
            "[38]\tvalid_0's multi_logloss: 1.11806\tvalid_0's multi_logloss: 1.11806\n",
            "[39]\tvalid_0's multi_logloss: 1.12719\tvalid_0's multi_logloss: 1.12719\n",
            "[40]\tvalid_0's multi_logloss: 1.12742\tvalid_0's multi_logloss: 1.12742\n",
            "[41]\tvalid_0's multi_logloss: 1.13204\tvalid_0's multi_logloss: 1.13204\n",
            "[42]\tvalid_0's multi_logloss: 1.13099\tvalid_0's multi_logloss: 1.13099\n",
            "[43]\tvalid_0's multi_logloss: 1.13081\tvalid_0's multi_logloss: 1.13081\n",
            "[44]\tvalid_0's multi_logloss: 1.13273\tvalid_0's multi_logloss: 1.13273\n",
            "[45]\tvalid_0's multi_logloss: 1.13689\tvalid_0's multi_logloss: 1.13689\n",
            "[46]\tvalid_0's multi_logloss: 1.14145\tvalid_0's multi_logloss: 1.14145\n",
            "[47]\tvalid_0's multi_logloss: 1.13984\tvalid_0's multi_logloss: 1.13984\n",
            "[48]\tvalid_0's multi_logloss: 1.15062\tvalid_0's multi_logloss: 1.15062\n",
            "[49]\tvalid_0's multi_logloss: 1.15344\tvalid_0's multi_logloss: 1.15344\n",
            "[50]\tvalid_0's multi_logloss: 1.16174\tvalid_0's multi_logloss: 1.16174\n",
            "[51]\tvalid_0's multi_logloss: 1.15952\tvalid_0's multi_logloss: 1.15952\n",
            "[52]\tvalid_0's multi_logloss: 1.1685\tvalid_0's multi_logloss: 1.1685\n",
            "[53]\tvalid_0's multi_logloss: 1.16567\tvalid_0's multi_logloss: 1.16567\n",
            "[54]\tvalid_0's multi_logloss: 1.17795\tvalid_0's multi_logloss: 1.17795\n",
            "[55]\tvalid_0's multi_logloss: 1.17723\tvalid_0's multi_logloss: 1.17723\n",
            "[56]\tvalid_0's multi_logloss: 1.17982\tvalid_0's multi_logloss: 1.17982\n",
            "[57]\tvalid_0's multi_logloss: 1.18321\tvalid_0's multi_logloss: 1.18321\n",
            "[58]\tvalid_0's multi_logloss: 1.19149\tvalid_0's multi_logloss: 1.19149\n",
            "[59]\tvalid_0's multi_logloss: 1.1952\tvalid_0's multi_logloss: 1.1952\n",
            "[60]\tvalid_0's multi_logloss: 1.2015\tvalid_0's multi_logloss: 1.2015\n",
            "[61]\tvalid_0's multi_logloss: 1.20769\tvalid_0's multi_logloss: 1.20769\n",
            "[62]\tvalid_0's multi_logloss: 1.21223\tvalid_0's multi_logloss: 1.21223\n",
            "[63]\tvalid_0's multi_logloss: 1.21161\tvalid_0's multi_logloss: 1.21161\n",
            "[64]\tvalid_0's multi_logloss: 1.2187\tvalid_0's multi_logloss: 1.2187\n",
            "[65]\tvalid_0's multi_logloss: 1.22907\tvalid_0's multi_logloss: 1.22907\n",
            "[66]\tvalid_0's multi_logloss: 1.23517\tvalid_0's multi_logloss: 1.23517\n",
            "[67]\tvalid_0's multi_logloss: 1.23798\tvalid_0's multi_logloss: 1.23798\n",
            "[68]\tvalid_0's multi_logloss: 1.23956\tvalid_0's multi_logloss: 1.23956\n",
            "[69]\tvalid_0's multi_logloss: 1.2499\tvalid_0's multi_logloss: 1.2499\n",
            "[70]\tvalid_0's multi_logloss: 1.25078\tvalid_0's multi_logloss: 1.25078\n",
            "[71]\tvalid_0's multi_logloss: 1.2501\tvalid_0's multi_logloss: 1.2501\n",
            "[72]\tvalid_0's multi_logloss: 1.25758\tvalid_0's multi_logloss: 1.25758\n",
            "[73]\tvalid_0's multi_logloss: 1.25329\tvalid_0's multi_logloss: 1.25329\n",
            "[74]\tvalid_0's multi_logloss: 1.26037\tvalid_0's multi_logloss: 1.26037\n",
            "[75]\tvalid_0's multi_logloss: 1.26113\tvalid_0's multi_logloss: 1.26113\n",
            "[76]\tvalid_0's multi_logloss: 1.26013\tvalid_0's multi_logloss: 1.26013\n",
            "[77]\tvalid_0's multi_logloss: 1.27098\tvalid_0's multi_logloss: 1.27098\n",
            "[78]\tvalid_0's multi_logloss: 1.27075\tvalid_0's multi_logloss: 1.27075\n",
            "[79]\tvalid_0's multi_logloss: 1.27903\tvalid_0's multi_logloss: 1.27903\n",
            "[80]\tvalid_0's multi_logloss: 1.28067\tvalid_0's multi_logloss: 1.28067\n",
            "[81]\tvalid_0's multi_logloss: 1.28295\tvalid_0's multi_logloss: 1.28295\n",
            "[82]\tvalid_0's multi_logloss: 1.28632\tvalid_0's multi_logloss: 1.28632\n",
            "[83]\tvalid_0's multi_logloss: 1.29019\tvalid_0's multi_logloss: 1.29019\n",
            "[84]\tvalid_0's multi_logloss: 1.29922\tvalid_0's multi_logloss: 1.29922\n",
            "[85]\tvalid_0's multi_logloss: 1.2987\tvalid_0's multi_logloss: 1.2987\n",
            "[86]\tvalid_0's multi_logloss: 1.3115\tvalid_0's multi_logloss: 1.3115\n",
            "[87]\tvalid_0's multi_logloss: 1.31235\tvalid_0's multi_logloss: 1.31235\n",
            "[88]\tvalid_0's multi_logloss: 1.32385\tvalid_0's multi_logloss: 1.32385\n",
            "[89]\tvalid_0's multi_logloss: 1.32807\tvalid_0's multi_logloss: 1.32807\n",
            "[90]\tvalid_0's multi_logloss: 1.33902\tvalid_0's multi_logloss: 1.33902\n",
            "[91]\tvalid_0's multi_logloss: 1.34385\tvalid_0's multi_logloss: 1.34385\n",
            "[92]\tvalid_0's multi_logloss: 1.3529\tvalid_0's multi_logloss: 1.3529\n",
            "[93]\tvalid_0's multi_logloss: 1.3605\tvalid_0's multi_logloss: 1.3605\n",
            "[94]\tvalid_0's multi_logloss: 1.3711\tvalid_0's multi_logloss: 1.3711\n",
            "[95]\tvalid_0's multi_logloss: 1.37484\tvalid_0's multi_logloss: 1.37484\n",
            "[96]\tvalid_0's multi_logloss: 1.37679\tvalid_0's multi_logloss: 1.37679\n",
            "[97]\tvalid_0's multi_logloss: 1.38044\tvalid_0's multi_logloss: 1.38044\n",
            "[98]\tvalid_0's multi_logloss: 1.39085\tvalid_0's multi_logloss: 1.39085\n",
            "[99]\tvalid_0's multi_logloss: 1.39326\tvalid_0's multi_logloss: 1.39326\n",
            "[100]\tvalid_0's multi_logloss: 1.39878\tvalid_0's multi_logloss: 1.39878\n",
            "[101]\tvalid_0's multi_logloss: 1.41215\tvalid_0's multi_logloss: 1.41215\n",
            "[102]\tvalid_0's multi_logloss: 1.4209\tvalid_0's multi_logloss: 1.4209\n",
            "[103]\tvalid_0's multi_logloss: 1.42695\tvalid_0's multi_logloss: 1.42695\n",
            "[104]\tvalid_0's multi_logloss: 1.43118\tvalid_0's multi_logloss: 1.43118\n",
            "[105]\tvalid_0's multi_logloss: 1.43778\tvalid_0's multi_logloss: 1.43778\n",
            "[106]\tvalid_0's multi_logloss: 1.43621\tvalid_0's multi_logloss: 1.43621\n",
            "[107]\tvalid_0's multi_logloss: 1.44551\tvalid_0's multi_logloss: 1.44551\n",
            "[108]\tvalid_0's multi_logloss: 1.45223\tvalid_0's multi_logloss: 1.45223\n",
            "[109]\tvalid_0's multi_logloss: 1.46205\tvalid_0's multi_logloss: 1.46205\n",
            "[110]\tvalid_0's multi_logloss: 1.47595\tvalid_0's multi_logloss: 1.47595\n",
            "[111]\tvalid_0's multi_logloss: 1.47382\tvalid_0's multi_logloss: 1.47382\n",
            "[112]\tvalid_0's multi_logloss: 1.48906\tvalid_0's multi_logloss: 1.48906\n",
            "[113]\tvalid_0's multi_logloss: 1.49987\tvalid_0's multi_logloss: 1.49987\n",
            "[114]\tvalid_0's multi_logloss: 1.50883\tvalid_0's multi_logloss: 1.50883\n",
            "[115]\tvalid_0's multi_logloss: 1.51897\tvalid_0's multi_logloss: 1.51897\n",
            "[116]\tvalid_0's multi_logloss: 1.53151\tvalid_0's multi_logloss: 1.53151\n",
            "[117]\tvalid_0's multi_logloss: 1.53803\tvalid_0's multi_logloss: 1.53803\n",
            "[118]\tvalid_0's multi_logloss: 1.54343\tvalid_0's multi_logloss: 1.54343\n",
            "[119]\tvalid_0's multi_logloss: 1.5571\tvalid_0's multi_logloss: 1.5571\n",
            "[120]\tvalid_0's multi_logloss: 1.56485\tvalid_0's multi_logloss: 1.56485\n",
            "[121]\tvalid_0's multi_logloss: 1.56742\tvalid_0's multi_logloss: 1.56742\n",
            "[122]\tvalid_0's multi_logloss: 1.569\tvalid_0's multi_logloss: 1.569\n",
            "[123]\tvalid_0's multi_logloss: 1.56962\tvalid_0's multi_logloss: 1.56962\n",
            "[124]\tvalid_0's multi_logloss: 1.57802\tvalid_0's multi_logloss: 1.57802\n",
            "[125]\tvalid_0's multi_logloss: 1.57565\tvalid_0's multi_logloss: 1.57565\n",
            "[126]\tvalid_0's multi_logloss: 1.59085\tvalid_0's multi_logloss: 1.59085\n",
            "[127]\tvalid_0's multi_logloss: 1.5953\tvalid_0's multi_logloss: 1.5953\n",
            "[128]\tvalid_0's multi_logloss: 1.60339\tvalid_0's multi_logloss: 1.60339\n",
            "[129]\tvalid_0's multi_logloss: 1.61032\tvalid_0's multi_logloss: 1.61032\n",
            "[130]\tvalid_0's multi_logloss: 1.61227\tvalid_0's multi_logloss: 1.61227\n",
            "[131]\tvalid_0's multi_logloss: 1.61829\tvalid_0's multi_logloss: 1.61829\n",
            "[132]\tvalid_0's multi_logloss: 1.62696\tvalid_0's multi_logloss: 1.62696\n",
            "[133]\tvalid_0's multi_logloss: 1.62751\tvalid_0's multi_logloss: 1.62751\n",
            "[134]\tvalid_0's multi_logloss: 1.63256\tvalid_0's multi_logloss: 1.63256\n",
            "[135]\tvalid_0's multi_logloss: 1.63872\tvalid_0's multi_logloss: 1.63872\n",
            "[136]\tvalid_0's multi_logloss: 1.65309\tvalid_0's multi_logloss: 1.65309\n",
            "[137]\tvalid_0's multi_logloss: 1.6679\tvalid_0's multi_logloss: 1.6679\n",
            "[138]\tvalid_0's multi_logloss: 1.67465\tvalid_0's multi_logloss: 1.67465\n",
            "Early stopping, best iteration is:\n",
            "[38]\tvalid_0's multi_logloss: 1.11806\tvalid_0's multi_logloss: 1.11806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.627906976744186"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U_Vnw6YWscW",
        "outputId": "fcb9dbdc-09af-430b-c8de-072abce172b4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.627906976744186"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "007SxzT9W6fw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}